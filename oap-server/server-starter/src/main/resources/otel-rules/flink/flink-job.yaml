# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This will parse a textual representation of a duration. The formats
# accepted are based on the ISO-8601 duration format {@code PnDTnHnMn.nS}
# with days considered to be exactly 24 hours.
# <p>
# Examples:
# <pre>
#    "PT20.345S" -- parses as "20.345 seconds"
#    "PT15M"     -- parses as "15 minutes" (where a minute is 60 seconds)
#    "PT10H"     -- parses as "10 hours" (where an hour is 3600 seconds)
#    "P2D"       -- parses as "2 days" (where a day is 24 hours or 86400 seconds)
#    "P2DT3H4M"  -- parses as "2 days, 3 hours and 4 minutes"
#    "P-6H3M"    -- parses as "-6 hours and +3 minutes"
#    "-P6H3M"    -- parses as "-6 hours and -3 minutes"
#    "-P-6H+3M"  -- parses as "+6 hours and -3 minutes"
# </pre>
filter: "{ tags -> tags.job_name == 'flink-jobManager-monitoring' || tags.job_name == 'flink-taskManager-monitoring' }" # The OpenTelemetry job name
expSuffix: tag({tags -> tags.cluster = 'flink::' + tags.cluster}).endpoint(['cluster'], ['flink_job_name'], Layer.FLINK)
metricPrefix: meter_flink_job

metricsRules:

  - name: restart_number
    exp: flink_jobmanager_job_numRestarts.sum(['cluster','flink_job_name'])
  - name: runningTime
    exp: flink_jobmanager_job_runningTime.sum(['cluster','flink_job_name'])
  - name: restartingTime
    exp: flink_jobmanager_job_restartingTime.sum(['cluster','flink_job_name'])
  - name: cancellingTime
    exp: flink_jobmanager_job_cancellingTime.sum(['cluster','flink_job_name'])

# checkpoints
  - name: checkpoints_total
    exp: flink_jobmanager_job_totalNumberOfCheckpoints.sum(['cluster','flink_job_name'])
  - name: checkpoints_failed
    exp: flink_jobmanager_job_numberOfFailedCheckpoints.sum(['cluster','flink_job_name'])
  - name: checkpoints_completed
    exp: flink_jobmanager_job_numberOfCompletedCheckpoints.sum(['cluster','flink_job_name'])
  - name: checkpoints_inProgress
    exp: flink_jobmanager_job_numberOfInProgressCheckpoints.sum(['cluster','flink_job_name'])
  - name: lastCheckpointSize
    exp: flink_jobmanager_job_lastCheckpointSize.sum(['cluster','flink_job_name'])
  - name: lastCheckpointDuration
    exp: flink_jobmanager_job_lastCheckpointDuration.sum(['cluster','flink_job_name'])

  - name: currentEmitEventTimeLag
    exp: flink_taskmanager_job_task_operator_currentEmitEventTimeLag.sum(['cluster','flink_job_name','operator_name'])

  - name: numRecordsIn
    exp: flink_taskmanager_job_task_operator_numRecordsIn.sum(['cluster','flink_job_name','operator_name'])
  - name: numRecordsOut
    exp: flink_taskmanager_job_task_operator_numRecordsOut.sum(['cluster','flink_job_name','operator_name'])
  - name: numBytesInPerSecond
    exp: flink_taskmanager_job_task_operator_numBytesInPerSecond.sum(['cluster','flink_job_name','operator_name'])
  - name: numBytesOutPerSecond
    exp: flink_taskmanager_job_task_operator_numBytesOutPerSecond.sum(['cluster','flink_job_name','operator_name'])


